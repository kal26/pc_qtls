{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling analysis\n",
    "\n",
    "subsample the number of inidvidualas/RNA-seq datasets and look at how number of signals changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "prefix = '/home/klawren/oak/pcqtls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the subsampled expression and covar files\n",
    "this only needs to be run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outputs from a config file\n",
    "config_path= f'{prefix}/config/proteincoding_main.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "tissue_id_path = config['tissue_id_path']\n",
    "clusters_dir = config['clusters_dir']\n",
    "expression_dir = config['expression_dir']\n",
    "covariates_dir = config['covariates_dir']\n",
    "\n",
    "tissue_df = pd.read_csv(f\"{prefix}/{tissue_id_path}\", header=0)\n",
    "tissue_ids = list(tissue_df['Tissue'])\n",
    "tissue_id = 'Cells_Cultured_fibroblasts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/klawren/oak/pcqtls/data/processed/subsampling/50'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_samples \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/processed/subsampling/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/covariates/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/normalized_expression/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/klawren/oak/pcqtls/data/processed/subsampling/50'"
     ]
    }
   ],
   "source": [
    "# minimum of 300 in each tissue, I'll do 100, 200, 300\n",
    "\n",
    "for num_samples in [50,100,200, 300]:\n",
    "    output_dir = f'{prefix}/data/processed/subsampling/{num_samples}'\n",
    "    os.mkdir(output_dir)\n",
    "    os.mkdir(f'{output_dir}/covariates/')\n",
    "    os.mkdir(f'{output_dir}/normalized_expression/')\n",
    "\n",
    "    for tissue_id in tissue_ids:\n",
    "        # load in each expression and covariates files\n",
    "        expression_df = pd.read_csv(f'{prefix}/{expression_dir}/{tissue_id}.v8.normalized_expression.bed', sep='\\t')\n",
    "        covariates_df = pd.read_csv(f'{prefix}/{covariates_dir}/{tissue_id}.v8.covariates.txt', sep='\\t', index_col=0).T\n",
    "\n",
    "        selected_samples = covariates_df.index[:num_samples].values\n",
    "\n",
    "        # write out first x as a subset\n",
    "        sub_expression = expression_df[np.concatenate([expression_df.columns[:4].values, selected_samples])]\n",
    "        sub_expression.to_csv(f'{output_dir}/normalized_expression/{tissue_id}.v8.normalized_expression.bed', sep='\\t', index=None)\n",
    "\n",
    "        sub_covar = covariates_df.loc[selected_samples]\n",
    "        sub_covar.T.to_csv(f'{output_dir}/covariates/{tissue_id}.v8.covariates.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with a random selection of 100 rather than the first 100\n",
    "for num_samples in [100]:\n",
    "    output_dir = f'{prefix}/data/processed/subsampling/{num_samples}_rand'\n",
    "    try:\n",
    "        os.mkdir(output_dir)\n",
    "        os.mkdir(f'{output_dir}/covariates/')\n",
    "        os.mkdir(f'{output_dir}/normalized_expression/')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    for tissue_id in tissue_ids:\n",
    "        # load in each expression and covariates files\n",
    "        expression_df = pd.read_csv(f'{prefix}/{expression_dir}/{tissue_id}.v8.normalized_expression.bed', sep='\\t')\n",
    "        covariates_df = pd.read_csv(f'{prefix}/{covariates_dir}/{tissue_id}.v8.covariates.txt', sep='\\t', index_col=0).T\n",
    "\n",
    "        selected_samples = pd.Series(covariates_df.index.values).sample(num_samples)\n",
    "\n",
    "        sub_expression = expression_df[np.concatenate([expression_df.columns[:4].values, selected_samples])]\n",
    "        sub_expression.to_csv(f'{output_dir}/normalized_expression/{tissue_id}.v8.normalized_expression.bed', sep='\\t', index=None)\n",
    "\n",
    "        sub_covar = covariates_df.loc[selected_samples]\n",
    "        sub_covar.T.to_csv(f'{output_dir}/covariates/{tissue_id}.v8.covariates.txt', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
