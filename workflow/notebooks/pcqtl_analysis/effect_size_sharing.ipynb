{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## effect size sharing for multi-gene qtls\n",
    "\n",
    "say we have a qtl that impacts multiple genes. How does the fractional effect of that qtl on each gene vary? w.r.t for instance distance from qtl to tss? maybe tie in ABC connections here? Maybe build a model that predicts how qtl impact on each gene will be split based on gene baseline expression, distance, ect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: The R output will not be colorized because it seems that your terminal does not support ANSI escape codes. isatty(stdout()) returned FALSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/klawren/oak/pcqtls/workflow/scripts')\n",
    "from notebook_helper_functions import *\n",
    "from annotate_clusters import *\n",
    "\n",
    "import upsetplot as up\n",
    "from tqdm.auto import tqdm  # for notebooks\n",
    "\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outputs from a config file\n",
    "prefix = '/home/klawren/oak/pcqtls'\n",
    "import yaml\n",
    "config_path= f'{prefix}/config/proteincoding_main.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# load in the tissue ids \n",
    "tissue_df = load_tissue_df(config)\n",
    "tissue_ids = list(tissue_df['Tissue'])\n",
    "\n",
    "# select just 1 tissue id to do for now \n",
    "my_tissue_id = 'Cells_Cultured_fibroblasts' # because only one cell type\n",
    "#tissue_ids = [tissue_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in data\n",
    "effect sizes for qtls\n",
    "overlap dfs\n",
    "gencode for tss starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_nominal = load_e_nominal(config, my_tissue_id, chr_id=22)\n",
    "pc_nominal = load_pc_nominal(config, my_tissue_id, chr_id=22)\n",
    "overlap = load_overlap(config, my_tissue_id)\n",
    "pc_susie = load_pc_susie(config, my_tissue_id)\n",
    "\n",
    "# set e_nominal to be index based on variant-cluster pairs\n",
    "e_nominal_cid = e_nominal.set_index('var_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at just one chr to start\n",
    "pc_susie['chr'] = pc_susie['variant_id'].str.split('chr').str[1].str.split('_').str[0]\n",
    "pc_susie = pc_susie[pc_susie['chr'] == '22']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the subset of varaints in pcqtl determined credible sets, and calculate the varience-explained on a per gene basis for each gene in the cluster and for the cluster-pc overall\n",
    "\n",
    "variance for each egene-cluster-credibleset(pc and cs num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variance(nominal_df):\n",
    "    nominal_df['variance'] = nominal_df['slope'].apply(np.square) * 100\n",
    "\n",
    "def get_var_explained(var_list, pip_list, nominal_df, cluster_id):\n",
    "    # make sure all varaints are in the nominal df\n",
    "    try:\n",
    "        nominal_df['variance']\n",
    "    except KeyError:\n",
    "        add_variance(nominal_df)\n",
    "    sub_nominal = nominal_df[(nominal_df['cluster_id'] == cluster_id)&nominal_df['variant_id'].isin(var_list)]\n",
    "    # add pips to the df    \n",
    "    sub_nominal = sub_nominal.merge(pd.Series(pip_list, index=pd.Series(var_list, name='variant_id'), name='pip'), on='variant_id')\n",
    "    sub_nominal['variance_weighted'] = sub_nominal['variance'] * sub_nominal['pip']\n",
    "    # sum over each phenotype to get the total weighted varience\n",
    "    return sub_nominal.groupby('phenotype_id').agg({'variance_weighted':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_grouped_pc_susie = pc_susie.groupby('cs_id').agg({'pip':list, \n",
    "                               'variant_id': list,\n",
    "                               'cs_num':'first',\n",
    "                               'pc_num':'first',\n",
    "                               'lead_variant_id':'first',\n",
    "                               'num_vars':'first',\n",
    "                               'cluster_id':'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a3c8dd58c7415285cda9ea45ae61e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, row in tqdm(cs_grouped_pc_susie.iterrows(), total=len(cs_grouped_pc_susie)):\n",
    "    pc_var_weighted = get_var_explained(row['variant_id'], row['pip'], pc_nominal, row['cluster_id'])\n",
    "    cs_grouped_pc_susie.loc[idx, 'matching_pc_var'] = pc_var_weighted[pc_var_weighted['phenotype_id'].str.split('_pc').str[-1] == str(row['pc_num'])].iloc[0]['variance_weighted']\n",
    "\n",
    "    e_var_weighted = get_var_explained(row['variant_id'], row['pip'], e_nominal, row['cluster_id'])\n",
    "    cs_grouped_pc_susie.loc[idx, 'e_vars'] = str(e_var_weighted['variance_weighted'].to_list())\n",
    "    cs_grouped_pc_susie.loc[idx, 'e_var_phenotypes'] = str(e_var_weighted['phenotype_id'].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_gencode, gid_gencode = load_gencode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the gene information (start and strand are what I need)\n",
    "full_gencode=pd.read_csv('/home/klawren/oak/pcqtls/data/references/processed_gencode.v26.GRCh38.genes.gtf', sep='\\t', skiprows=range(6), \n",
    "            header=None, names=['chr', 'dataset', 'type', 'start','end', '.', 'strand', 'na', 'info'])\n",
    "\n",
    "full_gencode = full_gencode[full_gencode['type']=='transcript']\n",
    "full_gencode['transcript_id'] = full_gencode['info'].str.split(';').str[1].str.split('\\\"').str[-2]\n",
    "\n",
    "# add in the start and end info\n",
    "full_gencode['tss_start'] = np.where(full_gencode['strand'] == '+', full_gencode['start'], full_gencode['end'])\n",
    "full_gencode['gene_end'] = np.where(full_gencode['strand'] == '-', full_gencode['start'], full_gencode['end'])\n",
    "\n",
    "# filter to just the transcripts that are in the clusters\n",
    "gene_ids = np.concatenate(overlap_df['cluster_id'].str.split('_'))\n",
    "gid_gencode = full_gencode.set_index('transcript_id').loc[gene_ids]\n",
    "gid_gencode = gid_gencode.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = sum_variance_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'egene_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/micromamba/envs/tensorqtl_r/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/micromamba/envs/tensorqtl_r/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/micromamba/envs/tensorqtl_r/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'egene_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m egene_tss \u001b[38;5;241m=\u001b[39m gid_gencode\u001b[38;5;241m.\u001b[39mloc[\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43megene_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtss_start\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/micromamba/envs/tensorqtl_r/lib/python3.8/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/tensorqtl_r/lib/python3.8/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/micromamba/envs/tensorqtl_r/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'egene_id'"
     ]
    }
   ],
   "source": [
    "egene_tss = gid_gencode.loc[row['egene_id']]['tss_start']\n",
    "lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
