import numpy as np
import pandas as pd
import argparse
from sklearn.decomposition import PCA
import os
import tensorqtl
import torch
from tensorqtl.core import Residualizer


def get_PC(ts, expression_df_gid, pc_num=1):
    # function to get PCs
    cluster = expression_df_gid.loc[ts.split(',')]
    X = cluster[cluster.columns[3:]].transpose()
    pca = PCA(n_components=pc_num)
    pca.fit(X)
    X_transformed = pca.transform(X)
    return X_transformed[:,pc_num-1]


# adapted from tensorqtl
def calculate_residual(phenotype_df, covariates_df, center=False):
    """Calculate normalized residual genotypes and phenotypes"""
    # set up residualize device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    residualizer = Residualizer(torch.tensor(covariates_df.values, dtype=torch.float32).to(device))
    phenotype_t = torch.tensor(phenotype_df.values, dtype=torch.float).to(device)

    # residualize
    phenotype_res_t = residualizer.transform(phenotype_t)  # phenotypes x samples

    # center and normalize
    if center:
        phenotype_res_t = tensorqtl.core.center_normalize(phenotype_res_t, dim=1)

    return phenotype_res_t.numpy()

def reformat_cluster_df(cluster_df, expression_df_gid, pc_num=1):
    # chromosome in different format
    cluster_df['#chr'] = 'chr' + cluster_df['Chromosome'].astype(str)

    # start and stop
    def get_start(ts):
        return expression_df_gid.loc[ts.split(',')]['start'].min()
    def get_end(ts):
        return expression_df_gid.loc[ts.split(',')]['end'].max()
    cluster_df['start'] = cluster_df['Transcripts'].apply(lambda x: get_start(x))
    cluster_df['end'] = cluster_df['Transcripts'].apply(lambda x: get_end(x))

    # cluster id "gene_id", sorted gene ids with '_' as seperator 
    # sorted so this matches the cluster id generated by the control eqtls
    cluster_df['gene_id'] = ['_'.join([*sorted(t.split(',')), f'pc{pc_num}']) for t in cluster_df['Transcripts']]
    return cluster_df


def make_bed_order(df):
    # the column order matters, so rearrange columns
    cols = list(df)
    cols.insert(0, cols.pop(cols.index('#chr')))
    cols.insert(1, cols.pop(cols.index('start')))
    cols.insert(2, cols.pop(cols.index('end')))
    cols.insert(3, cols.pop(cols.index('gene_id')))
    df = df.loc[:, cols]
    # sort positions
    df.sort_values(['start'], inplace=True)
    return df

def pc_bed(cluster_path, expression_path, covariates_path, pc_out_path, pc_num=1, verb=0):
    #   expression_path = f'/home/klawren/oak/coexp_eqtl/tami_eqtl_proejct/data/Whole_Blood.v8.normalized_expression.bed'
    #   cluster_path = f'/home/klawren/oak/coexp_eqtl/tami_eqtl_proejct/output/1_correlations/Whole_Blood/clusters_chr_21.csv'
    #   pc_path = f'{pc_out_prefix}.pc_1.chr{chr_id}.bed'
    #   pc_out_prefix=f'/home/klawren/oak/coexp_eqtl/output/3_eqtl_pcs/{tissue_id}/{tissue_id}'
    #   covariates_file = f'/home/klawren/oak/coexp_eqtl/tami_eqtl_proejct/data/{tissue_id}.v8.covariates.txt'

    # load in data
    if verb:
        print('loading data')
    cluster_df = pd.read_csv(cluster_path)
    cluster_orig_columns = cluster_df.columns.values
    expression_df = pd.read_csv(expression_path, sep='\t')
    covariates_df = pd.read_csv(covariates_path, sep='\t', index_col=0).T


    # add .bed info to cluster
    expression_df_gid = expression_df.set_index('gene_id')
    cluster_df = reformat_cluster_df(cluster_df, expression_df_gid, pc_num=pc_num)


    # residualize expression 
    residal_exp = calculate_residual(expression_df[expression_df.columns[4:]], covariates_df)
    expression_df_res = expression_df_gid.copy()
    expression_df_res[expression_df.columns[4:]] = residal_exp


    # get PCs  
    if verb:
        print('getting pcs')
    pcs = cluster_df['Transcripts'].apply(lambda x: get_PC(x, expression_df_res, pc_num=pc_num))


    # format into a df
    pc_df = pd.DataFrame(np.stack(pcs.tolist()), 
                         columns = expression_df.columns[4:], 
                         index = cluster_df.index)
    # add in ids, starts, and ends
    pc_df = pd.concat([cluster_df, pc_df], axis=1).drop(columns=cluster_orig_columns)
    pc_df = make_bed_order(pc_df)

    # write out bed pc file
    if verb:
        print('Writing out to {}'.format(pc_out_path))
    pc_df.to_csv(pc_out_path, sep='\t', index=False)

def main():
    # Parse arguments from cmd
    parser = argparse.ArgumentParser()
    parser.add_argument('-cl', '--cluster_path', help = 'path to .csv clusters')
    parser.add_argument('-e', '--expression_path', help = 'path to .bed normalized expression')
    parser.add_argument('-co', '--covariates_path', help = 'path to covariates')
    parser.add_argument('-o', '--pc_out_path', help = 'path where pc results should be written out')
    parser.add_argument('--pc_num', type=int, default=1, help = 'which number pc to write out')
    parser.add_argument('--verbosity', type=int, default=0, help = 'output verbosity')

    args = parser.parse_args()
    # call the pc funciton
    pc_bed(args.cluster_path, args.expression_path, args.covariates_path, args.pc_out_path, pc_num=args.pc_num, verb=args.verbosity)

if __name__ == "__main__":
    main()